{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp4xzIVmbrMftyArM4P1UW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asmaaad37/Machine-Learning/blob/main/Chatbot_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jRjqrr70aaT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('data.txt', 'r', errors = 'ignore')\n",
        "raw_doc = f.read()"
      ],
      "metadata": {
        "id": "55aRey251qhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_doc = raw_doc.lower() #lowercase\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BggSvOXY2Bcm",
        "outputId": "5de22271-aa0a-45b6-a5d2-62cb3a6407fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = nltk.sent_tokenize(raw_doc)\n",
        "word_tokens = nltk.word_tokenize(raw_doc)"
      ],
      "metadata": {
        "id": "w7lhCqHx20pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Tokenization!"
      ],
      "metadata": {
        "id": "Nx3kQ5cl3eAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_3LOLqm3c_n",
        "outputId": "26a4d0d6-034c-42a6-c57b-791a9ce81e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nmain menu\\n\\nwikipediathe free encyclopedia\\nsearch wikipedia\\nsearch\\ncreate account\\nlog in\\n\\npersonal tools\\ncontents hide\\n(top)\\nbackground\\ndevelopment\\napplication\\ntoggle application subsection\\nmessaging apps\\nas part of company apps and websites\\nchatbot sequences\\ncompany internal platforms\\ncustomer service\\nhealthcare\\npolitics\\ngovernment\\ntoys\\nmalicious use\\ndata security\\nlimitations of chatbots\\nchatbots and jobs\\nsee also\\nreferences\\nfurther reading\\nexternal links\\nchatbot\\n\\narticle\\ntalk\\nread\\nedit\\nview history\\n\\ntools\\nappearance hide\\ntext\\n\\nsmall\\n\\nstandard\\n\\nlarge\\nwidth\\n\\nstandard\\n\\nwide\\ncolor (beta)\\n\\nautomatic\\n\\nlight\\n\\ndark\\nreport an issue with dark mode\\nfrom wikipedia, the free encyclopedia\\nfor the bot-creation software, see chatbot.',\n",
              " 'for bots on internet relay chat, see irc bot.',\n",
              " 'parts of this article (those related to everything, particularly sections after the intro) need to be updated.',\n",
              " 'the reason given is: this article is using citations from 1970 and virtually all claims about conversational capabilities are at least ten years out of date (for example the turing test was arguably made obsolete years ago by transformer models).',\n",
              " 'please help update this article to reflect recent events or newly available information.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX3b0URz3mq9",
        "outputId": "96ba9ff6-8ab8-49e3-d2f5-e3f2b411cc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['main', 'menu', 'wikipediathe', 'free', 'encyclopedia']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing Text-PreProcessing Steps"
      ],
      "metadata": {
        "id": "a0BIRDWj3zIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "D83Ekz2o3vze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Greeting Functions"
      ],
      "metadata": {
        "id": "pg-GantT4ZsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "greet_inputs = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\")\n",
        "greet_responses = (\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\")\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in greet_inputs:\n",
        "      return random.choice(greet_responses)"
      ],
      "metadata": {
        "id": "xPOmPcWI4YhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response Generation by the BOT."
      ],
      "metadata": {
        "id": "L4E3bn114xl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "TOm0GaIO4wx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robot_reponse = ''\n",
        "  TfidVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "  tfidf = TfidVec.fit_transform(sentence_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf == 0):\n",
        "    robot_reponse = robot_reponse + \"I am sorry! I don't understand you\"\n",
        "    return robot_reponse\n",
        "  else:\n",
        "    robot_reponse = robot_reponse + sentence_tokens[idx]\n",
        "    return robot_reponse"
      ],
      "metadata": {
        "id": "KOO5Cd-r5K11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the ChatFLow."
      ],
      "metadata": {
        "id": "dtHLYJ4E-YF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "print('Hello! I am the Learning Bot. Start typing your text after greeting to talk to me. For ending the convo type bye!')\n",
        "while(flag == True):\n",
        "  user_response = input()\n",
        "  user_response = user_response.lower()\n",
        "  if(user_response != 'bye'):\n",
        "    if(user_response == 'thanks' or user_response == 'thank you'):\n",
        "      flag = False\n",
        "      print('Learning Bot: You are welcome!')\n",
        "    else:\n",
        "      if(greet(user_response) != None):\n",
        "        print('Learning Bot: ' + greet(user_response))\n",
        "      else:\n",
        "        sentence_tokens.append(user_response)\n",
        "        word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
        "        final_words = list(set(word_tokens))\n",
        "        print('Learning Bot: ', end = '')\n",
        "        print(response(user_response))\n",
        "        sentence_tokens.remove(user_response)\n",
        "  else:\n",
        "    flag = False\n",
        "    print('Learning Bot: Goodbye!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M55hxaiE-XGN",
        "outputId": "14ac0f82-ca2b-4b10-c528-c0c30205a34e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am the Learning Bot. Start typing your text after greeting to talk to me. For ending the convo type bye!\n",
            "bye\n",
            "Learning Bot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZlQ7ZmRARsq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}